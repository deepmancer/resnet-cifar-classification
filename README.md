# üñºÔ∏è Training ResNet-18 for CIFAR-10 Image Classification

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/Python-3.6+-3776AB.svg?style=for-the-badge&logo=Python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Scikit--learn-F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="Scikit-learn">
</p>

### About

This project implements ResNet-18 from scratch in PyTorch and trains it on the CIFAR-10 dataset to achieve high accuracy in image classification.

---

## üìù Project Description

This repository provides a complete implementation of the ResNet-18 architecture, a deep residual network renowned for its simplicity and effectiveness in image classification tasks. The model is trained on the CIFAR-10 dataset, which contains 60,000 32x32 color images in 10 classes. The focus of this project is to build and train the ResNet-18 model from the ground up, achieving high accuracy, and exploring the learned feature space of the model.

### üéØ Objectives

- **Model**: Implement the ResNet-18 architecture from scratch in PyTorch.
- **Task**: Train the model on the CIFAR-10 dataset to classify images into one of 10 categories.
- **Feature Exploration**: Visualize and analyze the feature space using t-SNE and k-Nearest Neighbors (k-NN) algorithms.

---

## üõ†Ô∏è Prerequisites

Ensure you have the following dependencies installed before running the project:

- **Python 3.6+**: The programming language used for the project.
- **PyTorch**: The deep learning framework employed for building and training ResNet-18.
- **Scikit-learn**: For implementing the t-SNE algorithm and k-NN classifiers.

Install the required libraries via pip:

```bash
pip install torch scikit-learn
```

---

## üìä Model Performance

The ResNet-18 model, after training on the CIFAR-10 dataset, achieves the following accuracy:

| Model             | Accuracy    |
| ----------------- | ----------- |
| [ResNet-18](https://arxiv.org/abs/1512.03385)  | **90.71%**  |

---

## üîç Exploring Feature Space

Understanding the feature space learned by a deep network can provide insights into how the model discriminates between different classes. In this project, we explore the outputs of the penultimate layer (one layer before the final classification layer) using the following methods:
- t-SNE
- k-NN

### Feature Space Definition

The feature space refers to the high-dimensional space where the outputs of the neurons in the layer just before the final classification layer reside. Visualizing this space provides valuable insights into the model's internal representations.

<p align="center">
  <img src="Images/feature_space.png" width="800" alt="Feature Space Visualization">
</p>


### üåÄ t-SNE Visualization

t-SNE (t-distributed Stochastic Neighbor Embedding) is used to reduce the dimensionality of the feature space and project it into a 2D plane for visualization. This technique helps in understanding how well the model separates different classes in the feature space.

<p align="center">
  <img src="Images/t-SNE.png" width="500" alt="t-SNE Visualization">
</p>

### üß© k-Nearest Neighbors (k-NN)

k-NN is applied to the feature space to explore the clustering of different classes. It helps in assessing the compactness and separability of the feature vectors generated by the model.

<p align="center">
  <img src="Images/knn.png" width="500" alt="k-NN Visualization">
</p>
